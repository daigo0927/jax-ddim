{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40e359ee-a91a-47b9-a98e-c075558786bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2021 NVIDIA Corporation\n",
      "Built on Mon_May__3_19:15:13_PDT_2021\n",
      "Cuda compilation tools, release 11.3, V11.3.109\n",
      "Build cuda_11.3.r11.3/compiler.29920130_0\n"
     ]
    }
   ],
   "source": [
    "! nvcc -V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac5145eb-911f-4cfd-a040-f8ca5290a90f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Jul 17 21:08:39 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 470.57.02    Driver Version: 470.57.02    CUDA Version: 11.4     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   34C    P0    37W / 300W |      0MiB / 16160MiB |      1%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "! nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0df68364-4c70-4701-bbd9-d0afa7d85b7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://storage.googleapis.com/jax-releases/jax_cuda_releases.html\n",
      "Collecting jax[cuda]\n",
      "  Downloading jax-0.3.14.tar.gz (990 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m990.1/990.1 kB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: absl-py in /opt/conda/lib/python3.7/site-packages (from jax[cuda]) (1.0.0)\n",
      "Requirement already satisfied: numpy>=1.19 in /opt/conda/lib/python3.7/site-packages (from jax[cuda]) (1.21.6)\n",
      "Requirement already satisfied: opt_einsum in /opt/conda/lib/python3.7/site-packages (from jax[cuda]) (3.3.0)\n",
      "Requirement already satisfied: scipy>=1.5 in /opt/conda/lib/python3.7/site-packages (from jax[cuda]) (1.7.3)\n",
      "Requirement already satisfied: typing_extensions in /opt/conda/lib/python3.7/site-packages (from jax[cuda]) (4.2.0)\n",
      "Collecting etils[epath]\n",
      "  Downloading etils-0.6.0-py3-none-any.whl (98 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.1/98.1 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting jaxlib==0.3.14+cuda11.cudnn82\n",
      "  Downloading https://storage.googleapis.com/jax-releases/cuda11/jaxlib-0.3.14%2Bcuda11.cudnn82-cp37-none-manylinux2014_x86_64.whl (161.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m161.9/161.9 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: flatbuffers<3.0,>=1.12 in /opt/conda/lib/python3.7/site-packages (from jaxlib==0.3.14+cuda11.cudnn82->jax[cuda]) (1.12)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from absl-py->jax[cuda]) (1.16.0)\n",
      "Requirement already satisfied: zipp in /opt/conda/lib/python3.7/site-packages (from etils[epath]->jax[cuda]) (3.8.0)\n",
      "Requirement already satisfied: importlib_resources in /opt/conda/lib/python3.7/site-packages (from etils[epath]->jax[cuda]) (5.7.1)\n",
      "Building wheels for collected packages: jax\n",
      "  Building wheel for jax (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for jax: filename=jax-0.3.14-py3-none-any.whl size=1147584 sha256=5054aa36a495231fb1dc2990a86bbff16f6be624fe927108b2ded8e908885865\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/e9/e3/55/b169c23c6b91c3d8c01bda07e6b9c61a1b7496227ec35fff27\n",
      "Successfully built jax\n",
      "Installing collected packages: etils, jaxlib, jax\n",
      "Successfully installed etils-0.6.0 jax-0.3.14 jaxlib-0.3.14+cuda11.cudnn82\n",
      "Collecting flax\n",
      "  Downloading flax-0.5.2-py3-none-any.whl (197 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m197.1/197.1 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting optax\n",
      "  Downloading optax-0.1.3-py3-none-any.whl (145 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m145.1/145.1 kB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=4.1.1 in /opt/conda/lib/python3.7/site-packages (from flax) (4.2.0)\n",
      "Requirement already satisfied: jax>=0.3.2 in /home/jupyter/.local/lib/python3.7/site-packages (from flax) (0.3.14)\n",
      "Requirement already satisfied: PyYAML>=5.4.1 in /opt/conda/lib/python3.7/site-packages (from flax) (6.0)\n",
      "Collecting msgpack\n",
      "  Downloading msgpack-1.0.4-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (299 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m299.8/299.8 kB\u001b[0m \u001b[31m30.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: matplotlib in /opt/conda/lib/python3.7/site-packages (from flax) (3.5.2)\n",
      "Collecting rich~=11.1\n",
      "  Downloading rich-11.2.0-py3-none-any.whl (217 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m217.3/217.3 kB\u001b[0m \u001b[31m29.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.12 in /opt/conda/lib/python3.7/site-packages (from flax) (1.21.6)\n",
      "Requirement already satisfied: scipy>=1.5 in /opt/conda/lib/python3.7/site-packages (from jax>=0.3.2->flax) (1.7.3)\n",
      "Requirement already satisfied: absl-py in /opt/conda/lib/python3.7/site-packages (from jax>=0.3.2->flax) (1.0.0)\n",
      "Requirement already satisfied: opt-einsum in /opt/conda/lib/python3.7/site-packages (from jax>=0.3.2->flax) (3.3.0)\n",
      "Requirement already satisfied: etils[epath] in /home/jupyter/.local/lib/python3.7/site-packages (from jax>=0.3.2->flax) (0.6.0)\n",
      "Requirement already satisfied: colorama<0.5.0,>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from rich~=11.1->flax) (0.4.4)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.6.0 in /opt/conda/lib/python3.7/site-packages (from rich~=11.1->flax) (2.12.0)\n",
      "Collecting commonmark<0.10.0,>=0.9.0\n",
      "  Downloading commonmark-0.9.1-py2.py3-none-any.whl (51 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.1/51.1 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->flax) (1.4.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib->flax) (0.11.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib->flax) (9.1.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib->flax) (4.33.3)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->flax) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.7/site-packages (from matplotlib->flax) (2.8.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib->flax) (21.3)\n",
      "Requirement already satisfied: jaxlib>=0.1.37 in /home/jupyter/.local/lib/python3.7/site-packages (from optax->flax) (0.3.14+cuda11.cudnn82)\n",
      "Collecting chex>=0.0.4\n",
      "  Downloading chex-0.1.3-py3-none-any.whl (72 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.2/72.2 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from absl-py->jax>=0.3.2->flax) (1.16.0)\n",
      "Collecting toolz>=0.9.0\n",
      "  Downloading toolz-0.12.0-py3-none-any.whl (55 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.8/55.8 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: dm-tree>=0.1.5 in /opt/conda/lib/python3.7/site-packages (from chex>=0.0.4->optax->flax) (0.1.7)\n",
      "Requirement already satisfied: flatbuffers<3.0,>=1.12 in /opt/conda/lib/python3.7/site-packages (from jaxlib>=0.1.37->optax->flax) (1.12)\n",
      "Requirement already satisfied: importlib_resources in /opt/conda/lib/python3.7/site-packages (from etils[epath]->jax>=0.3.2->flax) (5.7.1)\n",
      "Requirement already satisfied: zipp in /opt/conda/lib/python3.7/site-packages (from etils[epath]->jax>=0.3.2->flax) (3.8.0)\n",
      "Installing collected packages: msgpack, commonmark, toolz, rich, chex, optax, flax\n",
      "\u001b[33m  WARNING: The script cmark is installed in '/home/jupyter/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0mSuccessfully installed chex-0.1.3 commonmark-0.9.1 flax-0.5.2 msgpack-1.0.4 optax-0.1.3 rich-11.2.0 toolz-0.12.0\n",
      "flax                                  0.5.2\n",
      "jax                                   0.3.14\n",
      "jaxlib                                0.3.14+cuda11.cudnn82\n",
      "jupyter-server-mathjax                0.2.5\n",
      "optax                                 0.1.3\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import jax\n",
    "except ModuleNotFoundError:\n",
    "    ! pip install --user --upgrade \"jax[cuda]\" -f https://storage.googleapis.com/jax-releases/jax_cuda_releases.html\n",
    "    ! pip install --user flax\n",
    "    \n",
    "! pip list | grep ax    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7734cc6a-7046-4b37-ad73-0e1bbe8bf3da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████████████| 102/102 [00:28<00:00,  3.56it/s, loss=0.45821]\n",
      "Epoch 1: 100%|██████████████████| 102/102 [00:09<00:00, 11.26it/s, loss=0.35904]\n",
      "Epoch 2: 100%|██████████████████| 102/102 [00:09<00:00, 11.32it/s, loss=0.40192]\n",
      "Epoch 3: 100%|██████████████████| 102/102 [00:09<00:00, 11.32it/s, loss=0.30877]\n",
      "Epoch 4: 100%|██████████████████| 102/102 [00:09<00:00, 11.21it/s, loss=0.30582]\n",
      "Epoch 5: 100%|██████████████████| 102/102 [00:08<00:00, 11.34it/s, loss=0.29718]\n",
      "Epoch 6: 100%|██████████████████| 102/102 [00:08<00:00, 11.35it/s, loss=0.27016]\n",
      "Epoch 7: 100%|██████████████████| 102/102 [00:08<00:00, 11.34it/s, loss=0.26396]\n",
      "Epoch 8: 100%|██████████████████| 102/102 [00:08<00:00, 11.44it/s, loss=0.25777]\n",
      "Epoch 9: 100%|██████████████████| 102/102 [00:08<00:00, 11.41it/s, loss=0.26576]\n",
      "Epoch 10: 100%|█████████████████| 102/102 [00:08<00:00, 11.43it/s, loss=0.28782]\n",
      "Epoch 11: 100%|█████████████████| 102/102 [00:08<00:00, 11.52it/s, loss=0.27427]\n",
      "Epoch 12: 100%|█████████████████| 102/102 [00:09<00:00, 11.31it/s, loss=0.26260]\n",
      "Epoch 13: 100%|█████████████████| 102/102 [00:09<00:00, 11.31it/s, loss=0.26694]\n",
      "Epoch 14: 100%|█████████████████| 102/102 [00:09<00:00, 11.33it/s, loss=0.24734]\n",
      "Epoch 15: 100%|█████████████████| 102/102 [00:09<00:00, 11.28it/s, loss=0.24542]\n",
      "Epoch 16: 100%|█████████████████| 102/102 [00:08<00:00, 11.36it/s, loss=0.25032]\n",
      "Epoch 17: 100%|█████████████████| 102/102 [00:08<00:00, 11.35it/s, loss=0.24816]\n",
      "Epoch 18: 100%|█████████████████| 102/102 [00:09<00:00, 11.26it/s, loss=0.26158]\n",
      "Epoch 19: 100%|█████████████████| 102/102 [00:09<00:00, 11.26it/s, loss=0.24383]\n",
      "Epoch 20: 100%|█████████████████| 102/102 [00:08<00:00, 11.34it/s, loss=0.23557]\n",
      "Epoch 21: 100%|█████████████████| 102/102 [00:09<00:00, 11.17it/s, loss=0.23958]\n",
      "Epoch 22: 100%|█████████████████| 102/102 [00:08<00:00, 11.35it/s, loss=0.23921]\n",
      "Epoch 23: 100%|█████████████████| 102/102 [00:09<00:00, 11.25it/s, loss=0.23512]\n",
      "Epoch 24: 100%|█████████████████| 102/102 [00:08<00:00, 11.36it/s, loss=0.24621]\n",
      "Epoch 25: 100%|█████████████████| 102/102 [00:08<00:00, 11.36it/s, loss=0.24270]\n",
      "Epoch 26: 100%|█████████████████| 102/102 [00:08<00:00, 11.35it/s, loss=0.23100]\n",
      "Epoch 27: 100%|█████████████████| 102/102 [00:08<00:00, 11.44it/s, loss=0.24788]\n",
      "Epoch 28: 100%|█████████████████| 102/102 [00:08<00:00, 11.36it/s, loss=0.24345]\n",
      "Epoch 29: 100%|█████████████████| 102/102 [00:08<00:00, 11.41it/s, loss=0.24202]\n",
      "Epoch 30: 100%|█████████████████| 102/102 [00:08<00:00, 11.46it/s, loss=0.23482]\n",
      "Epoch 31: 100%|█████████████████| 102/102 [00:08<00:00, 11.43it/s, loss=0.22542]\n",
      "Epoch 32: 100%|█████████████████| 102/102 [00:09<00:00, 11.33it/s, loss=0.24425]\n",
      "Epoch 33: 100%|█████████████████| 102/102 [00:08<00:00, 11.38it/s, loss=0.24232]\n",
      "Epoch 34: 100%|█████████████████| 102/102 [00:09<00:00, 11.33it/s, loss=0.25201]\n",
      "Epoch 35: 100%|█████████████████| 102/102 [00:09<00:00, 11.12it/s, loss=0.23370]\n",
      "Epoch 36: 100%|█████████████████| 102/102 [00:09<00:00, 11.31it/s, loss=0.22826]\n",
      "Epoch 37: 100%|█████████████████| 102/102 [00:09<00:00, 11.33it/s, loss=0.22280]\n",
      "Epoch 38: 100%|█████████████████| 102/102 [00:08<00:00, 11.43it/s, loss=0.23344]\n",
      "Epoch 39: 100%|█████████████████| 102/102 [00:08<00:00, 11.40it/s, loss=0.23654]\n",
      "Epoch 40: 100%|█████████████████| 102/102 [00:08<00:00, 11.35it/s, loss=0.23196]\n",
      "Epoch 41: 100%|█████████████████| 102/102 [00:09<00:00, 11.30it/s, loss=0.23757]\n",
      "Epoch 42: 100%|█████████████████| 102/102 [00:08<00:00, 11.36it/s, loss=0.25867]\n",
      "Epoch 43: 100%|█████████████████| 102/102 [00:09<00:00, 11.26it/s, loss=0.25044]\n",
      "Epoch 44: 100%|█████████████████| 102/102 [00:08<00:00, 11.42it/s, loss=0.22690]\n",
      "Epoch 45: 100%|█████████████████| 102/102 [00:08<00:00, 11.48it/s, loss=0.24393]\n",
      "Epoch 46: 100%|█████████████████| 102/102 [00:08<00:00, 11.42it/s, loss=0.22752]\n",
      "Epoch 47: 100%|█████████████████| 102/102 [00:08<00:00, 11.50it/s, loss=0.23014]\n",
      "Epoch 48: 100%|█████████████████| 102/102 [00:08<00:00, 11.56it/s, loss=0.24794]\n",
      "Epoch 49: 100%|█████████████████| 102/102 [00:08<00:00, 11.37it/s, loss=0.23077]\n"
     ]
    }
   ],
   "source": [
    "! python train.py \\\n",
    "-e 50 \\\n",
    "--image-size 64 \\\n",
    "--batch-size 64 \\\n",
    "--learning-rate 0.0005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14c3e95-f5b8-4cc3-bcc5-64ca2e45c793",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow 2 (Local)",
   "language": "python",
   "name": "local-tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
